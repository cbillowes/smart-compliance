{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fraud reduction strategy for compliance and risk management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dfbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image_for_ocr(image_path):\n",
    "    # Preprocess the image to improve OCR accuracy\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    preprocessed_image_path = '/mnt/data/preprocessed_image.jpg'\n",
    "    cv2.imwrite(preprocessed_image_path, thresh)\n",
    "    return preprocessed_image_path\n",
    "\n",
    "def perform_ocr_on_image(image_path):\n",
    "    # Perform OCR on the given image and return the extracted text\n",
    "    preprocessed_image_path = preprocess_image_for_ocr(image_path)\n",
    "    extracted_text = pytesseract.image_to_string(Image.open(preprocessed_image_path))\n",
    "    return extracted_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aea27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def denoise_background(image_path, blur_intensity=5):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Apply Gaussian Blur to the image\n",
    "    blurred_image = cv2.GaussianBlur(img, (blur_intensity, blur_intensity), 0)\n",
    "\n",
    "    # Save the denoised image\n",
    "    denoised_background_path = '/mnt/data/denoised_background.jpg'\n",
    "    cv2.imwrite(denoised_background_path, blurred_image)\n",
    "\n",
    "    return denoised_background_path\n",
    "\n",
    "def denoise_id_and_face(image_path, diameter=9, sigmaColor=75, sigmaSpace=75):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Apply Bilateral Filter to the image\n",
    "    denoised_image = cv2.bilateralFilter(img, diameter, sigmaColor, sigmaSpace)\n",
    "\n",
    "    # Save the denoised image\n",
    "    denoised_id_face_path = '/mnt/data/denoised_id_face.jpg'\n",
    "    cv2.imwrite(denoised_id_face_path, denoised_image)\n",
    "\n",
    "    return denoised_id_face_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetector():\n",
    "\n",
    "    def __init__(self,faceCascadePath):\n",
    "        self.faceCascade=cv2.CascadeClassifier(f\"{cv2.data.haarcascades}{faceCascadePath}\")\n",
    "\n",
    "\n",
    "    def detect(self, image,\n",
    "               scaleFactor=1.1,\n",
    "               minNeighbors=5,\n",
    "               minSize=(30,30)):\n",
    "\n",
    "        #function return rectangle coordinates of faces for given image\n",
    "        rects=self.faceCascade.detectMultiScale(image,\n",
    "                                                scaleFactor=scaleFactor,\n",
    "                                                minNeighbors=minNeighbors,\n",
    "                                                minSize=minSize)\n",
    "        return rects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selfie with passport/ID\n",
    "\n",
    "Facial detection and recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade_path = \"haarcascade_frontalface_default.xml\"\n",
    "images = []\n",
    "for dirname, _, filenames in os.walk('./data/'):\n",
    "    for filename in filenames:\n",
    "        im = cv2.imread(os.path.join(dirname, filename))\n",
    "        images.append(im)\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    # #image converted to grayscale\n",
    "    gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # #face detection performed\n",
    "    faceRects=FaceDetector(faceCascadePath=face_cascade_path).detect(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30))\n",
    "\n",
    "    #faces drawn\n",
    "    for j, (x,y,w,h) in enumerate(faceRects):\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        cv2.imwrite(f\"./raw_data/detected_{i}_{j}.jpg\",image[y:y+h, x:x+w])\n",
    "\n",
    "    #image shown\n",
    "    plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photo passport/ID only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade_path = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "def detect_and_crop(folder, filename, image):\n",
    "  gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # #face detection performed\n",
    "  rectangles=FaceDetector(faceCascadePath=face_cascade_path).detect(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30))\n",
    "\n",
    "  #faces drawn\n",
    "  for i, (x,y,w,h) in enumerate(rectangles):\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    cv2.imwrite(f\"{folder}/{filename}_{i}.jpg\",image[y:y+h, x:x+w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists(\"./raw_data/output\") == False):\n",
    "  os.mkdir(\"./raw_data/output\")\n",
    "\n",
    "for dirname, _, filenames in os.walk('./raw_data/comparison/'):\n",
    "  for i, filename in enumerate(filenames):\n",
    "    if filename != '.DS_Store':\n",
    "      folder = f\"./raw_data/output/{os.path.basename(dirname)}\"\n",
    "\n",
    "      if (os.path.exists(folder) == False):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "      im = cv2.imread(os.path.join(dirname, filename))\n",
    "      detect_and_crop(folder, i, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DeepFace.verify(\"./raw_data/output/amit_passport_1/1_0.jpg\", \"./raw_data/output/amit_passport_1/2_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_path = \"\"\n",
    "img2_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "  \"VGG-Face\",\n",
    "  \"Facenet\",\n",
    "  \"Facenet512\",\n",
    "  \"OpenFace\",\n",
    "  \"DeepFace\",\n",
    "  \"DeepID\",\n",
    "  \"ArcFace\",\n",
    "  \"Dlib\",\n",
    "  \"SFace\",\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "  result = DeepFace.verify(img1_path=img1_path,\n",
    "      img2_path=img2_path,\n",
    "      model_name = model\n",
    "  )\n",
    "  print(model, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart-compliance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
